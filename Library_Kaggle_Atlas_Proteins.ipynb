{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from multiprocessing import Pool\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import keras\n",
    "\n",
    "import cv2\n",
    "import skimage\n",
    "from PIL import Image\n",
    "from imageio import imread\n",
    "from skimage.filters import sobel_h,sobel_v\n",
    "from skimage.measure import block_reduce\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_names = {\n",
    "    0:  \"Nucleoplasm\",  \n",
    "    1:  \"Nuclear membrane\",   \n",
    "    2:  \"Nucleoli\",   \n",
    "    3:  \"Nucleoli fibrillar center\",   \n",
    "    4:  \"Nuclear speckles\",\n",
    "    5:  \"Nuclear bodies\",   \n",
    "    6:  \"Endoplasmic reticulum\",   \n",
    "    7:  \"Golgi apparatus\",   \n",
    "    8:  \"Peroxisomes\",   \n",
    "    9:  \"Endosomes\",   \n",
    "    10:  \"Lysosomes\",   \n",
    "    11:  \"Intermediate filaments\",   \n",
    "    12:  \"Actin filaments\",   \n",
    "    13:  \"Focal adhesion sites\",   \n",
    "    14:  \"Microtubules\",   \n",
    "    15:  \"Microtubule ends\",   \n",
    "    16:  \"Cytokinetic bridge\",   \n",
    "    17:  \"Mitotic spindle\",   \n",
    "    18:  \"Microtubule organizing center\",   \n",
    "    19:  \"Centrosome\", \n",
    "    20:  \"Lipid droplets\",   \n",
    "    21:  \"Plasma membrane\",   \n",
    "    22:  \"Cell junctions\",   \n",
    "    23:  \"Mitochondria\",   \n",
    "    24:  \"Aggresome\",   \n",
    "    25:  \"Cytosol\",   \n",
    "    26:  \"Cytoplasmic bodies\",   \n",
    "    27:  \"Rods & rings\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reverse_train_labels = dict((v,k) for k,v in label_names.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_label(file_ids, train_labels):\n",
    "    l=train_labels[train_labels.Id.isin(file_ids)][\"Target\"].values\n",
    "    l= [[int(i) for i in s] for s in l]\n",
    "    labels = []\n",
    "    for i in l:\n",
    "        L = [0]*28\n",
    "        for j in i:\n",
    "            L[j]=1\n",
    "        labels.append(L)\n",
    "    return np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_targets(row):\n",
    "    row.Target = np.array(row.Target.split(\" \")).astype(np.int)\n",
    "    for num in row.Target:\n",
    "        name = label_names[int(num)]\n",
    "        row.loc[name] = 1\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad(image):\n",
    "    grad_x0=sobel_h(image[:,:,0])\n",
    "    grad_y0=sobel_v(image[:,:,0])\n",
    "    grad0=np.sqrt(grad_x0*grad_x0+grad_y0*grad_y0).T\n",
    "    \n",
    "    grad_x1=sobel_h(image[:,:,1])\n",
    "    grad_y1=sobel_v(image[:,:,1])\n",
    "    grad1=np.sqrt(grad_x1*grad_x1+grad_y1*grad_y1).T\n",
    "    \n",
    "    grad_x2=sobel_h(image[:,:,2])\n",
    "    grad_y2=sobel_v(image[:,:,2])\n",
    "    grad2=np.sqrt(grad_x2*grad_x2+grad_y2*grad_y2).T\n",
    "    \n",
    "    grad_x3=sobel_h(image[:,:,3])\n",
    "    grad_y3=sobel_v(image[:,:,3])\n",
    "    grad3=np.sqrt(grad_x3*grad_x3+grad_y3*grad_y3).T\n",
    "    \n",
    "    return np.array([grad0,grad1,grad2, grad3]).T\n",
    "\n",
    "def grad_threshold(image, eps):\n",
    "    \n",
    "    return (grad(image) > eps)*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dirrectional_grad(image,theta):\n",
    "    \n",
    "    grad_x0 = np.cos(theta)*sobel_h(image[:,:,0]) + np.sin(theta)*sobel_v(image[:,:,0])\n",
    "    grad_x1 = np.cos(theta)*sobel_h(image[:,:,1]) + np.sin(theta)*sobel_v(image[:,:,1])\n",
    "    grad_x2 = np.cos(theta)*sobel_h(image[:,:,2]) + np.sin(theta)*sobel_v(image[:,:,2])\n",
    "    grad_x3 = np.cos(theta)*sobel_h(image[:,:,3]) + np.sin(theta)*sobel_v(image[:,:,3])\n",
    "    \n",
    "    grad0= np.maximum(grad_x0,0).T\n",
    "    grad1= np.maximum(grad_x1,0).T\n",
    "    grad2= np.maximum(grad_x2,0).T\n",
    "    grad3= np.maximum(grad_x3,0).T\n",
    "    image= np.array([grad0,grad1,grad2, grad3]).T\n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(basepath, image_id):\n",
    "\n",
    "    images = np.zeros(shape=(512,512,4))\n",
    "    images[:,:,0] = imread(basepath + \"/\" + image_id + \"_green\" + \".png\")\n",
    "    images[:,:,1] = imread(basepath + \"/\" + image_id + \"_red\" + \".png\")\n",
    "    images[:,:,2] = imread(basepath + \"/\" + image_id + \"_blue\" + \".png\")\n",
    "    images[:,:,3] = imread(basepath + \"/\" + image_id + \"_yellow\" + \".png\")\n",
    "\n",
    "    return images\n",
    "\n",
    "    \n",
    "def make_title(file_id, train_labels):\n",
    "    file_targets = train_labels.loc[train_labels.Id==file_id, \"Target\"].values[0]\n",
    "    title = \" - \"\n",
    "    for n in file_targets:\n",
    "        title += label_names[n] + \" - \"\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_name(img):\n",
    "    name=[]\n",
    "    l=list(label_names.values())\n",
    "    j=0\n",
    "    for i in labels[img]:\n",
    "        if i==1:\n",
    "            name.append(l[j])\n",
    "        j+=1\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_image_row(image, subax, title, i ):\n",
    "    subax[0].imshow(image[:,:,4*i], cmap=\"Greens\")\n",
    "    subax[1].imshow(image[:,:,4*i+1], cmap=\"Reds\")\n",
    "    subax[1].set_title(\"stained microtubules\")\n",
    "    subax[2].imshow(image[:,:,4*i+2], cmap=\"Blues\")\n",
    "    subax[2].set_title(\"stained nucleus\")\n",
    "    subax[3].imshow(image[:,:,4*i+3], cmap=\"Oranges\")\n",
    "    subax[3].set_title(\"stained endoplasmatic reticulum\")\n",
    "    subax[0].set_title(title)\n",
    "    return subax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetGroupIterator:\n",
    "    \n",
    "    def __init__(self, target_names, batch_size, labels_path, basepath, ws, grad, dir_grad, grad_threshold, nb_threshold, nb_rot, ):\n",
    "        \n",
    "        self.target_names = '39c89a8e-bbb6-11e8-b2ba-ac1f6b6435d0'\n",
    "        self.target_list = [reverse_train_labels[key] for key in target_names]\n",
    "        self.batch_shape = (batch_size, 512, 512, 4)\n",
    "        self.basepath = basepath\n",
    "        self.train_labels = pd.read_csv(labels_path)\n",
    "        self.train_labels = self.train_labels.apply(fill_targets, axis=1)\n",
    "        self.ws = ws\n",
    "        self.grad = grad\n",
    "        self.dir_grad = dir_grad\n",
    "        self.grad_threshold = grad_threshold\n",
    "        self.nb_threshold = nb_threshold \n",
    "        self.nb_rot = nb_rot\n",
    "        \n",
    "    def features_aumentation(self, image):    \n",
    "\n",
    "        grad_=self.grad\n",
    "        dir_grad_=self.dir_grad\n",
    "        grad_threshold_=self.grad_threshold\n",
    "\n",
    "        a=image\n",
    "\n",
    "        if grad_:\n",
    "            a=np.append(a,grad(image), axis=2)\n",
    "\n",
    "        if dir_grad_:\n",
    "            rot=np.arange(0, 360, 360//self.nb_rot)\n",
    "            for i in rot:\n",
    "                a=np.append(a,dirrectional_grad(image,i), axis=2)\n",
    "\n",
    "        if grad_threshold_:\n",
    "            eps=np.arange(0,128,128//self.nb_threshold)\n",
    "            for e in eps:      \n",
    "                a=np.append(a, grad_threshold(image,e), axis=2)\n",
    "\n",
    "        return a\n",
    "    \n",
    "    def find_matching_data_entries(self):\n",
    "\n",
    "        self.train_labels[\"check_col\"] = self.train_labels.Target.apply(\n",
    "            lambda l: self.check_subset(l)\n",
    "        )\n",
    "        self.images_identifier = self.train_labels[self.train_labels.check_col==1].Id.values\n",
    "        self.train_labels.drop(\"check_col\", axis=1, inplace=True)\n",
    "    \n",
    "    def check_subset(self, targets):\n",
    "        return np.where(set(self.target_list).issuperset(set(targets)), 1, 0)\n",
    "    \n",
    "    def get_loader(self):\n",
    "\n",
    "        filenames = []\n",
    "        idx = 0\n",
    "        images = np.zeros(self.batch_shape)\n",
    "        p = Pool(processes=self.ws)\n",
    "        for image_id in self.images_identifier:\n",
    "            images[idx,:,:,:] = load_image(self.basepath, image_id)\n",
    "            filenames.append(image_id)\n",
    "            idx += 1\n",
    "            if idx == self.batch_shape[0]:\n",
    "                images = np.array(p.map(self.features_aumentation, images))\n",
    "                yield filenames, get_label(filenames,self.train_labels), images\n",
    "                filenames = []\n",
    "                images = np.zeros(self.batch_shape)\n",
    "                idx = 0\n",
    "        \n",
    "        if idx > 0:\n",
    "\n",
    "            images = np.array(p.map(self.features_aumentation, images))\n",
    "\n",
    "            yield filenames, get_label(filenames,self.train_labels), images\n",
    "        p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Load_data:\n",
    "    \n",
    "    def __init__(self, batch_size, labels_path, basepath, ws, grad, dir_grad, grad_threshold, nb_threshold, nb_rot, reduce, block_size):\n",
    "        \n",
    "        self.list_IDs = list_IDs\n",
    "        self.on_epoch_end()\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_shape = (batch_size, 512, 512, 4)\n",
    "        self.basepath = basepath\n",
    "        self.labels = pd.read_csv(labels_path)\n",
    "        self.ws = ws\n",
    "        self.grad = grad\n",
    "        self.dir_grad = dir_grad\n",
    "        self.grad_threshold = grad_threshold\n",
    "        self.nb_threshold = nb_threshold \n",
    "        self.nb_rot = nb_rot\n",
    "        self.reduce = reduce\n",
    "        self.block_size = block_size\n",
    "    \n",
    "    def reduce(self, images):\n",
    "        block=(1,block_size,block_size,1)\n",
    "        return block_reduce(images,block,np.mean)\n",
    "        \n",
    "    def features_aumentation(self, image):    \n",
    "\n",
    "        grad_=self.grad\n",
    "        dir_grad_=self.dir_grad\n",
    "        grad_threshold_=self.grad_threshold\n",
    "\n",
    "        a=image\n",
    "\n",
    "        if grad_:\n",
    "            a=np.append(a,grad(image), axis=2)\n",
    "\n",
    "        if dir_grad_:\n",
    "            rot=np.arange(0, 360, 360//self.nb_rot)\n",
    "            for i in rot:\n",
    "                a=np.append(a,dirrectional_grad(image,i), axis=2)\n",
    "\n",
    "        if grad_threshold_:\n",
    "            eps=np.arange(0,128,128//self.nb_threshold)\n",
    "            for e in eps:      \n",
    "                a=np.append(a, grad_threshold(image,e), axis=2)\n",
    "\n",
    "        return a\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def get_targets_per_image(self, identifier):\n",
    "        return self.labels.loc[self.labels.Id==identifier].drop(\n",
    "                [\"Id\", \"Target\", \"number_of_targets\"], axis=1).values\n",
    "    \n",
    "    def get_loader(self):\n",
    "\n",
    "        filenames = []\n",
    "        idx = 0\n",
    "        images = np.zeros(self.batch_shape)\n",
    "        p = Pool(processes=self.ws)\n",
    "        for image_id in self.images_identifier:\n",
    "            images[idx,:,:,:] = load_image(self.basepath, image_id)\n",
    "            filenames.append(image_id)\n",
    "            idx += 1\n",
    "            if idx == self.batch_shape[0]:\n",
    "                images = np.array(p.map(self.features_aumentation, images))\n",
    "                if self.reduce:\n",
    "                    yield filenames, get_label(filenames,self.labels), reduce(images)\n",
    "                else:\n",
    "                    yield filenames, get_label(filenames,self.labels), images\n",
    "                \n",
    "                filenames = []\n",
    "                images = np.zeros(self.batch_shape)\n",
    "                idx = 0\n",
    "        \n",
    "        if idx > 0:\n",
    "\n",
    "            images = np.array(p.map(self.features_aumentation, images))\n",
    "            if self.reduce:\n",
    "                yield filenames, get_label(filenames,self.labels), reduce(images)\n",
    "            else:\n",
    "                yield filenames, get_label(filenames,self.labels), images\n",
    "        p.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
